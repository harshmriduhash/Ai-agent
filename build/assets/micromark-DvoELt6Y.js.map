{"version":3,"file":"micromark-DvoELt6Y.js","sources":["../../node_modules/micromark/lib/initialize/content.js","../../node_modules/micromark/lib/initialize/document.js","../../node_modules/micromark/lib/initialize/flow.js","../../node_modules/micromark/lib/initialize/text.js","../../node_modules/micromark/lib/constructs.js","../../node_modules/micromark/lib/create-tokenizer.js","../../node_modules/micromark/lib/parse.js","../../node_modules/micromark/lib/postprocess.js","../../node_modules/micromark/lib/preprocess.js"],"sourcesContent":["/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Initializer}\n *   Content.\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(this.parser.constructs.contentInitial, afterContentStartConstruct, paragraphInitial);\n  /** @type {Token} */\n  let previous;\n  return contentStart;\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    return factorySpace(effects, contentStart, \"linePrefix\");\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter(\"paragraph\");\n    return lineStart(code);\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter(\"chunkText\", {\n      contentType: \"text\",\n      previous\n    });\n    if (previous) {\n      previous.next = token;\n    }\n    previous = token;\n    return data(code);\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit(\"chunkText\");\n      effects.exit(\"paragraph\");\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      effects.exit(\"chunkText\");\n      return lineStart;\n    }\n\n    // Data.\n    effects.consume(code);\n    return data;\n  }\n}","/**\n * @import {\n *   Construct,\n *   ContainerState,\n *   InitialConstruct,\n *   Initializer,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n *   Construct and its state.\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { splice } from 'micromark-util-chunked';\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n};\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeDocument(effects) {\n  const self = this;\n  /** @type {Array<StackItem>} */\n  const stack = [];\n  let continued = 0;\n  /** @type {TokenizeContext | undefined} */\n  let childFlow;\n  /** @type {Token | undefined} */\n  let childToken;\n  /** @type {number} */\n  let lineStartOffset;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued];\n      self.containerState = item[1];\n      return effects.attempt(item[0].continuation, documentContinue, checkNewContainers)(code);\n    }\n\n    // Done.\n    return checkNewContainers(code);\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++;\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined;\n      if (childFlow) {\n        closeFlow();\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          point = self.events[indexBeforeFlow][1].end;\n          break;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      let index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n      return checkNewContainers(code);\n    }\n    return start(code);\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code);\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code);\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack);\n    }\n\n    // Check if there is a new container.\n    self.containerState = {};\n    return effects.check(containerConstruct, thereIsANewContainer, thereIsNoNewContainer)(code);\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow();\n    exitContainers(continued);\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length;\n    lineStartOffset = self.now().offset;\n    return flowStart(code);\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {};\n    return effects.attempt(containerConstruct, containerContinue, flowStart)(code);\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++;\n    stack.push([self.currentConstruct, self.containerState]);\n    // Try another.\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow();\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    childFlow = childFlow || self.parser.flow(self.now());\n    effects.enter(\"chunkFlow\", {\n      _tokenizer: childFlow,\n      contentType: \"flow\",\n      previous: childToken\n    });\n    return flowContinue(code);\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit(\"chunkFlow\"), true);\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      writeToChild(effects.exit(\"chunkFlow\"));\n      // Get ready for the next line.\n      continued = 0;\n      self.interrupt = undefined;\n      return start;\n    }\n    effects.consume(code);\n    return flowContinue;\n  }\n\n  /**\n   * @param {Token} token\n   *   Token.\n   * @param {boolean | undefined} [endOfFile]\n   *   Whether the token is at the end of the file (default: `false`).\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function writeToChild(token, endOfFile) {\n    const stream = self.sliceStream(token);\n    if (endOfFile) stream.push(null);\n    token.previous = childToken;\n    if (childToken) childToken.next = token;\n    childToken = token;\n    childFlow.defineSkip(token.start);\n    childFlow.write(stream);\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length;\n      while (index--) {\n        if (\n        // The token starts before the line ending…\n        childFlow.events[index][1].start.offset < lineStartOffset && (\n        // …and either is not ended yet…\n        !childFlow.events[index][1].end ||\n        // …or ends after it.\n        childFlow.events[index][1].end.offset > lineStartOffset)) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return;\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {boolean | undefined} */\n      let seen;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end;\n            break;\n          }\n          seen = true;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n    }\n  }\n\n  /**\n   * @param {number} size\n   *   Size.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function exitContainers(size) {\n    let index = stack.length;\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index];\n      self.containerState = entry[1];\n      entry[0].exit.call(self, effects);\n    }\n    stack.length = size;\n  }\n  function closeFlow() {\n    childFlow.write([null]);\n    childToken = undefined;\n    childFlow = undefined;\n    self.containerState._closeFlow = undefined;\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n *   Tokenizer.\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(effects, effects.attempt(this.parser.constructs.document, ok, nok), \"linePrefix\", this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4);\n}","/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nimport { blankLine, content } from 'micromark-core-commonmark';\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeFlow(effects) {\n  const self = this;\n  const initial = effects.attempt(\n  // Try to parse a blank line.\n  blankLine, atBlankEnding,\n  // Try to parse initial flow (essentially, only code).\n  effects.attempt(this.parser.constructs.flowInitial, afterConstruct, factorySpace(effects, effects.attempt(this.parser.constructs.flow, afterConstruct, effects.attempt(content, afterConstruct)), \"linePrefix\")));\n  return initial;\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEndingBlank\");\n    effects.consume(code);\n    effects.exit(\"lineEndingBlank\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n}","/**\n * @import {\n *   Code,\n *   InitialConstruct,\n *   Initializer,\n *   Resolver,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nexport const resolver = {\n  resolveAll: createResolver()\n};\nexport const string = initializeFactory('string');\nexport const text = initializeFactory('text');\n\n/**\n * @param {'string' | 'text'} field\n *   Field.\n * @returns {InitialConstruct}\n *   Construct.\n */\nfunction initializeFactory(field) {\n  return {\n    resolveAll: createResolver(field === 'text' ? resolveAllLineSuffixes : undefined),\n    tokenize: initializeText\n  };\n\n  /**\n   * @this {TokenizeContext}\n   *   Context.\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this;\n    const constructs = this.parser.constructs[field];\n    const text = effects.attempt(constructs, start, notText);\n    return start;\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code);\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code);\n        return;\n      }\n      effects.enter(\"data\");\n      effects.consume(code);\n      return data;\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit(\"data\");\n        return text(code);\n      }\n\n      // Data.\n      effects.consume(code);\n      return data;\n    }\n\n    /**\n     * @param {Code} code\n     *   Code.\n     * @returns {boolean}\n     *   Whether the code is a break.\n     */\n    function atBreak(code) {\n      if (code === null) {\n        return true;\n      }\n      const list = constructs[code];\n      let index = -1;\n      if (list) {\n        // Always populated by defaults.\n\n        while (++index < list.length) {\n          const item = list[index];\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true;\n          }\n        }\n      }\n      return false;\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n *   Resolver.\n * @returns {Resolver}\n *   Resolver.\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText;\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1;\n    /** @type {number | undefined} */\n    let enter;\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === \"data\") {\n          enter = index;\n          index++;\n        }\n      } else if (!events[index] || events[index][1].type !== \"data\") {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end;\n          events.splice(enter + 2, index - enter - 2);\n          index = enter + 2;\n        }\n        enter = undefined;\n      }\n    }\n    return extraResolver ? extraResolver(events, context) : events;\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0; // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if ((eventIndex === events.length || events[eventIndex][1].type === \"lineEnding\") && events[eventIndex - 1][1].type === \"data\") {\n      const data = events[eventIndex - 1][1];\n      const chunks = context.sliceStream(data);\n      let index = chunks.length;\n      let bufferIndex = -1;\n      let size = 0;\n      /** @type {boolean | undefined} */\n      let tabs;\n      while (index--) {\n        const chunk = chunks[index];\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length;\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++;\n            bufferIndex--;\n          }\n          if (bufferIndex) break;\n          bufferIndex = -1;\n        }\n        // Number\n        else if (chunk === -2) {\n          tabs = true;\n          size++;\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++;\n          break;\n        }\n      }\n      if (size) {\n        const token = {\n          type: eventIndex === events.length || tabs || size < 2 ? \"lineSuffix\" : \"hardBreakTrailing\",\n          start: {\n            _bufferIndex: index ? bufferIndex : data.start._bufferIndex + bufferIndex,\n            _index: data.start._index + index,\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size\n          },\n          end: {\n            ...data.end\n          }\n        };\n        data.end = {\n          ...token.start\n        };\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token);\n        } else {\n          events.splice(eventIndex, 0, ['enter', token, context], ['exit', token, context]);\n          eventIndex += 2;\n        }\n      }\n      eventIndex++;\n    }\n  }\n  return events;\n}","/**\n * @import {Extension} from 'micromark-util-types'\n */\n\nimport { attention, autolink, blockQuote, characterEscape, characterReference, codeFenced, codeIndented, codeText, definition, hardBreakEscape, headingAtx, htmlFlow, htmlText, labelEnd, labelStartImage, labelStartLink, lineEnding, list, setextUnderline, thematicBreak } from 'micromark-core-commonmark';\nimport { resolver as resolveText } from './initialize/text.js';\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n};\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [91]: definition\n};\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n};\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n};\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n};\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n};\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {\n  null: [attention, resolveText]\n};\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {\n  null: [42, 95]\n};\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {\n  null: []\n};","/**\n * @import {\n *   Chunk,\n *   Code,\n *   ConstructRecord,\n *   Construct,\n *   Effects,\n *   InitialConstruct,\n *   ParseContext,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @callback Restore\n *   Restore the state.\n * @returns {undefined}\n *   Nothing.\n *\n * @typedef Info\n *   Info.\n * @property {Restore} restore\n *   Restore.\n * @property {number} from\n *   From.\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n *   Construct.\n * @param {Info} info\n *   Info.\n * @returns {undefined}\n *   Nothing.\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { push, splice } from 'micromark-util-chunked';\nimport { resolveAll } from 'micromark-util-resolve-all';\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n *   Parser.\n * @param {InitialConstruct} initialize\n *   Construct.\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n *   Point (optional).\n * @returns {TokenizeContext}\n *   Context.\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = {\n    _bufferIndex: -1,\n    _index: 0,\n    line: from && from.line || 1,\n    column: from && from.column || 1,\n    offset: from && from.offset || 0\n  };\n  /** @type {Record<string, number>} */\n  const columnStart = {};\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = [];\n  /** @type {Array<Chunk>} */\n  let chunks = [];\n  /** @type {Array<Token>} */\n  let stack = [];\n  /** @type {boolean | undefined} */\n  let consumed = true;\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    consume,\n    enter,\n    exit,\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  };\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    code: null,\n    containerState: {},\n    defineSkip,\n    events: [],\n    now,\n    parser,\n    previous: null,\n    sliceSerialize,\n    sliceStream,\n    write\n  };\n\n  /**\n   * The state function.\n   *\n   * @type {State | undefined}\n   */\n  let state = initialize.tokenize.call(context, effects);\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode;\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  }\n  return context;\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice);\n    main();\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n    addResult(initialize, 0);\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context);\n    return context.events;\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs);\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    } = point;\n    return {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    };\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex;\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index];\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   *   Code.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function go(code) {\n    consumed = undefined;\n    expectedCode = code;\n    state = state(code);\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++;\n\n      // At end of string chunk.\n      if (point._bufferIndex ===\n      // Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      /** @type {string} */\n      chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code;\n\n    // Mark as consumed.\n    consumed = true;\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore();\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   *   Callback.\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   *   Fields.\n   */\n  function constructFactory(onreturn, fields) {\n    return hook;\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | ConstructRecord | Construct} constructs\n     *   Constructs.\n     * @param {State} returnState\n     *   State.\n     * @param {State | undefined} [bogusState]\n     *   State.\n     * @returns {State}\n     *   State.\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {ReadonlyArray<Construct>} */\n      let listOfConstructs;\n      /** @type {number} */\n      let constructIndex;\n      /** @type {Construct} */\n      let currentConstruct;\n      /** @type {Info} */\n      let info;\n      return Array.isArray(constructs) ? /* c8 ignore next 1 */\n      handleListOfConstructs(constructs) : 'tokenize' in constructs ?\n      // Looks like a construct.\n      handleListOfConstructs([(/** @type {Construct} */constructs)]) : handleMapOfConstructs(constructs);\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleMapOfConstructs(map) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          const left = code !== null && map[code];\n          const all = code !== null && map.null;\n          const list = [\n          // To do: add more extension tests.\n          /* c8 ignore next 2 */\n          ...(Array.isArray(left) ? left : left ? [left] : []), ...(Array.isArray(all) ? all : all ? [all] : [])];\n          return handleListOfConstructs(list)(code);\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ReadonlyArray<Construct>} list\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n        if (list.length === 0) {\n          return bogusState;\n        }\n        return handleConstruct(list[constructIndex]);\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       *   Construct.\n       * @returns {State}\n       *   State.\n       */\n      function handleConstruct(construct) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          // Always populated by defaults.\n\n          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {\n            return nok(code);\n          }\n          return construct.tokenize.call(\n          // If we do have fields, create an object w/ `context` as its\n          // prototype.\n          // This allows a “live binding”, which is needed for `interrupt`.\n          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true;\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true;\n        info.restore();\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n        return bogusState;\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   *   Construct.\n   * @param {number} from\n   *   From.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct);\n    }\n    if (construct.resolve) {\n      splice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   *   Info.\n   */\n  function store() {\n    const startPoint = now();\n    const startPrevious = context.previous;\n    const startCurrentConstruct = context.currentConstruct;\n    const startEventsIndex = context.events.length;\n    const startStack = Array.from(stack);\n    return {\n      from: startEventsIndex,\n      restore\n    };\n\n    /**\n     * Restore state.\n     *\n     * @returns {undefined}\n     *   Nothing.\n     */\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {Pick<Token, 'end' | 'start'>} token\n *   Token.\n * @returns {Array<Chunk>}\n *   Chunks.\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index;\n  const startBufferIndex = token.start._bufferIndex;\n  const endIndex = token.end._index;\n  const endBufferIndex = token.end._bufferIndex;\n  /** @type {Array<Chunk>} */\n  let view;\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];\n  } else {\n    view = chunks.slice(startIndex, endIndex);\n    if (startBufferIndex > -1) {\n      const head = view[0];\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex);\n      } else {\n        view.shift();\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex));\n    }\n  }\n  return view;\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {boolean | undefined} [expandTabs=false]\n *   Whether to expand tabs (default: `false`).\n * @returns {string}\n *   Result.\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1;\n  /** @type {Array<string>} */\n  const result = [];\n  /** @type {boolean | undefined} */\n  let atTab;\n  while (++index < chunks.length) {\n    const chunk = chunks[index];\n    /** @type {string} */\n    let value;\n    if (typeof chunk === 'string') {\n      value = chunk;\n    } else switch (chunk) {\n      case -5:\n        {\n          value = \"\\r\";\n          break;\n        }\n      case -4:\n        {\n          value = \"\\n\";\n          break;\n        }\n      case -3:\n        {\n          value = \"\\r\" + \"\\n\";\n          break;\n        }\n      case -2:\n        {\n          value = expandTabs ? \" \" : \"\\t\";\n          break;\n        }\n      case -1:\n        {\n          if (!expandTabs && atTab) continue;\n          value = \" \";\n          break;\n        }\n      default:\n        {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk);\n        }\n    }\n    atTab = chunk === -2;\n    result.push(value);\n  }\n  return result.join('');\n}","/**\n * @import {\n *   Create,\n *   FullNormalizedExtension,\n *   InitialConstruct,\n *   ParseContext,\n *   ParseOptions\n * } from 'micromark-util-types'\n */\n\nimport { combineExtensions } from 'micromark-util-combine-extensions';\nimport { content } from './initialize/content.js';\nimport { document } from './initialize/document.js';\nimport { flow } from './initialize/flow.js';\nimport { string, text } from './initialize/text.js';\nimport * as defaultConstructs from './constructs.js';\nimport { createTokenizer } from './create-tokenizer.js';\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n *   Configuration (optional).\n * @returns {ParseContext}\n *   Parser.\n */\nexport function parse(options) {\n  const settings = options || {};\n  const constructs = /** @type {FullNormalizedExtension} */\n  combineExtensions([defaultConstructs, ...(settings.extensions || [])]);\n\n  /** @type {ParseContext} */\n  const parser = {\n    constructs,\n    content: create(content),\n    defined: [],\n    document: create(document),\n    flow: create(flow),\n    lazy: {},\n    string: create(string),\n    text: create(text)\n  };\n  return parser;\n\n  /**\n   * @param {InitialConstruct} initial\n   *   Construct to start with.\n   * @returns {Create}\n   *   Create a tokenizer.\n   */\n  function create(initial) {\n    return creator;\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from);\n    }\n  }\n}","/**\n * @import {Event} from 'micromark-util-types'\n */\n\nimport { subtokenize } from 'micromark-util-subtokenize';\n\n/**\n * @param {Array<Event>} events\n *   Events.\n * @returns {Array<Event>}\n *   Events.\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n  return events;\n}","/**\n * @import {Chunk, Code, Encoding, Value} from 'micromark-util-types'\n */\n\n/**\n * @callback Preprocessor\n *   Preprocess a value.\n * @param {Value} value\n *   Value.\n * @param {Encoding | null | undefined} [encoding]\n *   Encoding when `value` is a typed array (optional).\n * @param {boolean | null | undefined} [end=false]\n *   Whether this is the last chunk (default: `false`).\n * @returns {Array<Chunk>}\n *   Chunks.\n */\n\nconst search = /[\\0\\t\\n\\r]/g;\n\n/**\n * @returns {Preprocessor}\n *   Preprocess a value.\n */\nexport function preprocess() {\n  let column = 1;\n  let buffer = '';\n  /** @type {boolean | undefined} */\n  let start = true;\n  /** @type {boolean | undefined} */\n  let atCarriageReturn;\n  return preprocessor;\n\n  /** @type {Preprocessor} */\n  // eslint-disable-next-line complexity\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = [];\n    /** @type {RegExpMatchArray | null} */\n    let match;\n    /** @type {number} */\n    let next;\n    /** @type {number} */\n    let startPosition;\n    /** @type {number} */\n    let endPosition;\n    /** @type {Code} */\n    let code;\n    value = buffer + (typeof value === 'string' ? value.toString() : new TextDecoder(encoding || undefined).decode(value));\n    startPosition = 0;\n    buffer = '';\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++;\n      }\n      start = undefined;\n    }\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition;\n      match = search.exec(value);\n      endPosition = match && match.index !== undefined ? match.index : value.length;\n      code = value.charCodeAt(endPosition);\n      if (!match) {\n        buffer = value.slice(startPosition);\n        break;\n      }\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3);\n        atCarriageReturn = undefined;\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5);\n          atCarriageReturn = undefined;\n        }\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition));\n          column += endPosition - startPosition;\n        }\n        switch (code) {\n          case 0:\n            {\n              chunks.push(65533);\n              column++;\n              break;\n            }\n          case 9:\n            {\n              next = Math.ceil(column / 4) * 4;\n              chunks.push(-2);\n              while (column++ < next) chunks.push(-1);\n              break;\n            }\n          case 10:\n            {\n              chunks.push(-4);\n              column = 1;\n              break;\n            }\n          default:\n            {\n              atCarriageReturn = true;\n              column = 1;\n            }\n        }\n      }\n      startPosition = endPosition + 1;\n    }\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5);\n      if (buffer) chunks.push(buffer);\n      chunks.push(null);\n    }\n    return chunks;\n  }\n}"],"names":["content","initializeContent","effects","contentStart","afterContentStartConstruct","paragraphInitial","previous","code","factorySpace","lineStart","token","data","markdownLineEnding","document","initializeDocument","containerConstruct","tokenizeContainer","self","stack","continued","childFlow","childToken","lineStartOffset","start","item","documentContinue","checkNewContainers","closeFlow","indexBeforeExits","indexBeforeFlow","point","exitContainers","index","splice","documentContinued","flowStart","thereIsANewContainer","thereIsNoNewContainer","containerContinue","flowContinue","writeToChild","endOfFile","stream","seen","size","entry","ok","nok","flow","initializeFlow","initial","blankLine","atBlankEnding","afterConstruct","resolver","createResolver","string","initializeFactory","text","field","resolveAllLineSuffixes","initializeText","constructs","notText","atBreak","list","extraResolver","resolveAllText","events","context","enter","eventIndex","chunks","bufferIndex","tabs","chunk","blockQuote","contentInitial","definition","flowInitial","codeIndented","headingAtx","thematicBreak","setextUnderline","htmlFlow","codeFenced","characterReference","characterEscape","lineEnding","labelStartImage","attention","autolink","htmlText","labelStartLink","hardBreakEscape","labelEnd","codeText","insideSpan","resolveText","attentionMarkers","disable","createTokenizer","parser","initialize","from","columnStart","resolveAllConstructs","constructFactory","onsuccessfulconstruct","onsuccessfulcheck","consume","exit","defineSkip","now","sliceSerialize","sliceStream","write","state","slice","push","main","addResult","resolveAll","expandTabs","serializeChunks","sliceChunks","_bufferIndex","_index","line","column","offset","value","accountForPotentialSkip","chunkIndex","go","type","fields","construct","info","_","onreturn","hook","returnState","bogusState","listOfConstructs","constructIndex","currentConstruct","handleListOfConstructs","handleMapOfConstructs","map","left","all","handleConstruct","store","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","restore","startIndex","startBufferIndex","endIndex","endBufferIndex","view","head","result","atTab","parse","options","combineExtensions","defaultConstructs","create","creator","postprocess","subtokenize","search","preprocess","buffer","atCarriageReturn","preprocessor","encoding","end","match","next","startPosition","endPosition"],"mappings":"slBAaO,MAAMA,GAAU,CACrB,SAAUC,EACZ,EAQA,SAASA,GAAkBC,EAAS,CAClC,MAAMC,EAAeD,EAAQ,QAAQ,KAAK,OAAO,WAAW,eAAgBE,EAA4BC,CAAgB,EAExH,IAAIC,EACJ,OAAOH,EAGP,SAASC,EAA2BG,EAAM,CACxC,GAAIA,IAAS,KAAM,CACjBL,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAAL,EAAQ,MAAM,YAAY,EAC1BA,EAAQ,QAAQK,CAAI,EACpBL,EAAQ,KAAK,YAAY,EAClBM,EAAaN,EAASC,EAAc,YAAY,CAC3D,CAGE,SAASE,EAAiBE,EAAM,CAC9B,OAAAL,EAAQ,MAAM,WAAW,EAClBO,EAAUF,CAAI,CACzB,CAGE,SAASE,EAAUF,EAAM,CACvB,MAAMG,EAAQR,EAAQ,MAAM,YAAa,CACvC,YAAa,OACb,SAAAI,CACN,CAAK,EACD,OAAIA,IACFA,EAAS,KAAOI,GAElBJ,EAAWI,EACJC,EAAKJ,CAAI,CACpB,CAGE,SAASI,EAAKJ,EAAM,CAClB,GAAIA,IAAS,KAAM,CACjBL,EAAQ,KAAK,WAAW,EACxBA,EAAQ,KAAK,WAAW,EACxBA,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAIK,EAAmBL,CAAI,GACzBL,EAAQ,QAAQK,CAAI,EACpBL,EAAQ,KAAK,WAAW,EACjBO,IAITP,EAAQ,QAAQK,CAAI,EACbI,EACX,CACA,CCvDO,MAAME,GAAW,CACtB,SAAUC,EACZ,EAGMC,GAAqB,CACzB,SAAUC,EACZ,EAQA,SAASF,GAAmBZ,EAAS,CACnC,MAAMe,EAAO,KAEPC,EAAQ,CAAE,EAChB,IAAIC,EAAY,EAEZC,EAEAC,EAEAC,EACJ,OAAOC,EAGP,SAASA,EAAMhB,EAAM,CAWnB,GAAIY,EAAYD,EAAM,OAAQ,CAC5B,MAAMM,EAAON,EAAMC,CAAS,EAC5B,OAAAF,EAAK,eAAiBO,EAAK,CAAC,EACrBtB,EAAQ,QAAQsB,EAAK,CAAC,EAAE,aAAcC,EAAkBC,CAAkB,EAAEnB,CAAI,CAC7F,CAGI,OAAOmB,EAAmBnB,CAAI,CAClC,CAGE,SAASkB,EAAiBlB,EAAM,CAM9B,GALAY,IAKIF,EAAK,eAAe,WAAY,CAClCA,EAAK,eAAe,WAAa,OAC7BG,GACFO,EAAW,EAKb,MAAMC,EAAmBX,EAAK,OAAO,OACrC,IAAIY,EAAkBD,EAElBE,EAGJ,KAAOD,KACL,GAAIZ,EAAK,OAAOY,CAAe,EAAE,CAAC,IAAM,QAAUZ,EAAK,OAAOY,CAAe,EAAE,CAAC,EAAE,OAAS,YAAa,CACtGC,EAAQb,EAAK,OAAOY,CAAe,EAAE,CAAC,EAAE,IACxC,KACV,CAEME,EAAeZ,CAAS,EAGxB,IAAIa,EAAQJ,EACZ,KAAOI,EAAQf,EAAK,OAAO,QACzBA,EAAK,OAAOe,CAAK,EAAE,CAAC,EAAE,IAAM,CAC1B,GAAGF,CACJ,EACDE,IAIF,OAAAC,EAAOhB,EAAK,OAAQY,EAAkB,EAAG,EAAGZ,EAAK,OAAO,MAAMW,CAAgB,CAAC,EAG/EX,EAAK,OAAO,OAASe,EACdN,EAAmBnB,CAAI,CACpC,CACI,OAAOgB,EAAMhB,CAAI,CACrB,CAGE,SAASmB,EAAmBnB,EAAM,CAMhC,GAAIY,IAAcD,EAAM,OAAQ,CAI9B,GAAI,CAACE,EACH,OAAOc,EAAkB3B,CAAI,EAM/B,GAAIa,EAAU,kBAAoBA,EAAU,iBAAiB,SAC3D,OAAOe,EAAU5B,CAAI,EAQvBU,EAAK,UAAY,GAAQG,EAAU,kBAAoB,CAACA,EAAU,8BACxE,CAGI,OAAAH,EAAK,eAAiB,CAAE,EACjBf,EAAQ,MAAMa,GAAoBqB,EAAsBC,CAAqB,EAAE9B,CAAI,CAC9F,CAGE,SAAS6B,EAAqB7B,EAAM,CAClC,OAAIa,GAAWO,EAAW,EAC1BI,EAAeZ,CAAS,EACjBe,EAAkB3B,CAAI,CACjC,CAGE,SAAS8B,EAAsB9B,EAAM,CACnC,OAAAU,EAAK,OAAO,KAAKA,EAAK,IAAK,EAAC,IAAI,EAAIE,IAAcD,EAAM,OACxDI,EAAkBL,EAAK,IAAG,EAAG,OACtBkB,EAAU5B,CAAI,CACzB,CAGE,SAAS2B,EAAkB3B,EAAM,CAE/B,OAAAU,EAAK,eAAiB,CAAE,EACjBf,EAAQ,QAAQa,GAAoBuB,EAAmBH,CAAS,EAAE5B,CAAI,CACjF,CAGE,SAAS+B,EAAkB/B,EAAM,CAC/B,OAAAY,IACAD,EAAM,KAAK,CAACD,EAAK,iBAAkBA,EAAK,cAAc,CAAC,EAEhDiB,EAAkB3B,CAAI,CACjC,CAGE,SAAS4B,EAAU5B,EAAM,CACvB,GAAIA,IAAS,KAAM,CACba,GAAWO,EAAW,EAC1BI,EAAe,CAAC,EAChB7B,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAAa,EAAYA,GAAaH,EAAK,OAAO,KAAKA,EAAK,KAAK,EACpDf,EAAQ,MAAM,YAAa,CACzB,WAAYkB,EACZ,YAAa,OACb,SAAUC,CAChB,CAAK,EACMkB,EAAahC,CAAI,CAC5B,CAGE,SAASgC,EAAahC,EAAM,CAC1B,GAAIA,IAAS,KAAM,CACjBiC,EAAatC,EAAQ,KAAK,WAAW,EAAG,EAAI,EAC5C6B,EAAe,CAAC,EAChB7B,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAIK,EAAmBL,CAAI,GACzBL,EAAQ,QAAQK,CAAI,EACpBiC,EAAatC,EAAQ,KAAK,WAAW,CAAC,EAEtCiB,EAAY,EACZF,EAAK,UAAY,OACVM,IAETrB,EAAQ,QAAQK,CAAI,EACbgC,EACX,CAUE,SAASC,EAAa9B,EAAO+B,EAAW,CACtC,MAAMC,EAASzB,EAAK,YAAYP,CAAK,EAyCrC,GAxCI+B,GAAWC,EAAO,KAAK,IAAI,EAC/BhC,EAAM,SAAWW,EACbA,IAAYA,EAAW,KAAOX,GAClCW,EAAaX,EACbU,EAAU,WAAWV,EAAM,KAAK,EAChCU,EAAU,MAAMsB,CAAM,EAmClBzB,EAAK,OAAO,KAAKP,EAAM,MAAM,IAAI,EAAG,CACtC,IAAIsB,EAAQZ,EAAU,OAAO,OAC7B,KAAOY,KACL,GAEAZ,EAAU,OAAOY,CAAK,EAAE,CAAC,EAAE,MAAM,OAASV,IAE1C,CAACF,EAAU,OAAOY,CAAK,EAAE,CAAC,EAAE,KAE5BZ,EAAU,OAAOY,CAAK,EAAE,CAAC,EAAE,IAAI,OAASV,GAGtC,OAMJ,MAAMM,EAAmBX,EAAK,OAAO,OACrC,IAAIY,EAAkBD,EAElBe,EAEAb,EAGJ,KAAOD,KACL,GAAIZ,EAAK,OAAOY,CAAe,EAAE,CAAC,IAAM,QAAUZ,EAAK,OAAOY,CAAe,EAAE,CAAC,EAAE,OAAS,YAAa,CACtG,GAAIc,EAAM,CACRb,EAAQb,EAAK,OAAOY,CAAe,EAAE,CAAC,EAAE,IACxC,KACZ,CACUc,EAAO,EACjB,CAMM,IAJAZ,EAAeZ,CAAS,EAGxBa,EAAQJ,EACDI,EAAQf,EAAK,OAAO,QACzBA,EAAK,OAAOe,CAAK,EAAE,CAAC,EAAE,IAAM,CAC1B,GAAGF,CACJ,EACDE,IAIFC,EAAOhB,EAAK,OAAQY,EAAkB,EAAG,EAAGZ,EAAK,OAAO,MAAMW,CAAgB,CAAC,EAG/EX,EAAK,OAAO,OAASe,CAC3B,CACA,CAQE,SAASD,EAAea,EAAM,CAC5B,IAAIZ,EAAQd,EAAM,OAGlB,KAAOc,KAAUY,GAAM,CACrB,MAAMC,EAAQ3B,EAAMc,CAAK,EACzBf,EAAK,eAAiB4B,EAAM,CAAC,EAC7BA,EAAM,CAAC,EAAE,KAAK,KAAK5B,EAAMf,CAAO,CACtC,CACIgB,EAAM,OAAS0B,CACnB,CACE,SAASjB,GAAY,CACnBP,EAAU,MAAM,CAAC,IAAI,CAAC,EACtBC,EAAa,OACbD,EAAY,OACZH,EAAK,eAAe,WAAa,MACrC,CACA,CAQA,SAASD,GAAkBd,EAAS4C,EAAIC,EAAK,CAG3C,OAAOvC,EAAaN,EAASA,EAAQ,QAAQ,KAAK,OAAO,WAAW,SAAU4C,EAAIC,CAAG,EAAG,aAAc,KAAK,OAAO,WAAW,QAAQ,KAAK,SAAS,cAAc,EAAI,OAAY,CAAC,CACpL,CC5VO,MAAMC,GAAO,CAClB,SAAUC,EACZ,EAQA,SAASA,GAAe/C,EAAS,CAC/B,MAAMe,EAAO,KACPiC,EAAUhD,EAAQ,QAExBiD,GAAWC,EAEXlD,EAAQ,QAAQ,KAAK,OAAO,WAAW,YAAamD,EAAgB7C,EAAaN,EAASA,EAAQ,QAAQ,KAAK,OAAO,WAAW,KAAMmD,EAAgBnD,EAAQ,QAAQF,GAASqD,CAAc,CAAC,EAAG,YAAY,CAAC,CAAC,EAChN,OAAOH,EAGP,SAASE,EAAc7C,EAAM,CAC3B,GAAIA,IAAS,KAAM,CACjBL,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAAL,EAAQ,MAAM,iBAAiB,EAC/BA,EAAQ,QAAQK,CAAI,EACpBL,EAAQ,KAAK,iBAAiB,EAC9Be,EAAK,iBAAmB,OACjBiC,CACX,CAGE,SAASG,EAAe9C,EAAM,CAC5B,GAAIA,IAAS,KAAM,CACjBL,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAAL,EAAQ,MAAM,YAAY,EAC1BA,EAAQ,QAAQK,CAAI,EACpBL,EAAQ,KAAK,YAAY,EACzBe,EAAK,iBAAmB,OACjBiC,CACX,CACA,CC9CO,MAAMI,GAAW,CACtB,WAAYC,GAAc,CAC5B,EACaC,GAASC,GAAkB,QAAQ,EACnCC,GAAOD,GAAkB,MAAM,EAQ5C,SAASA,GAAkBE,EAAO,CAChC,MAAO,CACL,WAAYJ,GAAeI,IAAU,OAASC,GAAyB,MAAS,EAChF,SAAUC,CACX,EAOD,SAASA,EAAe3D,EAAS,CAC/B,MAAMe,EAAO,KACP6C,EAAa,KAAK,OAAO,WAAWH,CAAK,EACzCD,EAAOxD,EAAQ,QAAQ4D,EAAYvC,EAAOwC,CAAO,EACvD,OAAOxC,EAGP,SAASA,EAAMhB,EAAM,CACnB,OAAOyD,EAAQzD,CAAI,EAAImD,EAAKnD,CAAI,EAAIwD,EAAQxD,CAAI,CACtD,CAGI,SAASwD,EAAQxD,EAAM,CACrB,GAAIA,IAAS,KAAM,CACjBL,EAAQ,QAAQK,CAAI,EACpB,MACR,CACM,OAAAL,EAAQ,MAAM,MAAM,EACpBA,EAAQ,QAAQK,CAAI,EACbI,CACb,CAGI,SAASA,EAAKJ,EAAM,CAClB,OAAIyD,EAAQzD,CAAI,GACdL,EAAQ,KAAK,MAAM,EACZwD,EAAKnD,CAAI,IAIlBL,EAAQ,QAAQK,CAAI,EACbI,EACb,CAQI,SAASqD,EAAQzD,EAAM,CACrB,GAAIA,IAAS,KACX,MAAO,GAET,MAAM0D,EAAOH,EAAWvD,CAAI,EAC5B,IAAIyB,EAAQ,GACZ,GAAIiC,EAGF,KAAO,EAAEjC,EAAQiC,EAAK,QAAQ,CAC5B,MAAMzC,EAAOyC,EAAKjC,CAAK,EACvB,GAAI,CAACR,EAAK,UAAYA,EAAK,SAAS,KAAKP,EAAMA,EAAK,QAAQ,EAC1D,MAAO,EAEnB,CAEM,MAAO,EACb,CACA,CACA,CAQA,SAASsC,GAAeW,EAAe,CACrC,OAAOC,EAGP,SAASA,EAAeC,EAAQC,EAAS,CACvC,IAAIrC,EAAQ,GAERsC,EAIJ,KAAO,EAAEtC,GAASoC,EAAO,QACnBE,IAAU,OACRF,EAAOpC,CAAK,GAAKoC,EAAOpC,CAAK,EAAE,CAAC,EAAE,OAAS,SAC7CsC,EAAQtC,EACRA,MAEO,CAACoC,EAAOpC,CAAK,GAAKoC,EAAOpC,CAAK,EAAE,CAAC,EAAE,OAAS,UAEjDA,IAAUsC,EAAQ,IACpBF,EAAOE,CAAK,EAAE,CAAC,EAAE,IAAMF,EAAOpC,EAAQ,CAAC,EAAE,CAAC,EAAE,IAC5CoC,EAAO,OAAOE,EAAQ,EAAGtC,EAAQsC,EAAQ,CAAC,EAC1CtC,EAAQsC,EAAQ,GAElBA,EAAQ,QAGZ,OAAOJ,EAAgBA,EAAcE,EAAQC,CAAO,EAAID,CAC5D,CACA,CAaA,SAASR,GAAuBQ,EAAQC,EAAS,CAC/C,IAAIE,EAAa,EAEjB,KAAO,EAAEA,GAAcH,EAAO,QAC5B,IAAKG,IAAeH,EAAO,QAAUA,EAAOG,CAAU,EAAE,CAAC,EAAE,OAAS,eAAiBH,EAAOG,EAAa,CAAC,EAAE,CAAC,EAAE,OAAS,OAAQ,CAC9H,MAAM5D,EAAOyD,EAAOG,EAAa,CAAC,EAAE,CAAC,EAC/BC,EAASH,EAAQ,YAAY1D,CAAI,EACvC,IAAIqB,EAAQwC,EAAO,OACfC,EAAc,GACd7B,EAAO,EAEP8B,EACJ,KAAO1C,KAAS,CACd,MAAM2C,EAAQH,EAAOxC,CAAK,EAC1B,GAAI,OAAO2C,GAAU,SAAU,CAE7B,IADAF,EAAcE,EAAM,OACbA,EAAM,WAAWF,EAAc,CAAC,IAAM,IAC3C7B,IACA6B,IAEF,GAAIA,EAAa,MACjBA,EAAc,EACxB,SAEiBE,IAAU,GACjBD,EAAO,GACP9B,YACS+B,IAAU,GAEd,CAEL3C,IACA,KACV,CACA,CACM,GAAIY,EAAM,CACR,MAAMlC,EAAQ,CACZ,KAAM6D,IAAeH,EAAO,QAAUM,GAAQ9B,EAAO,EAAI,aAAe,oBACxE,MAAO,CACL,aAAcZ,EAAQyC,EAAc9D,EAAK,MAAM,aAAe8D,EAC9D,OAAQ9D,EAAK,MAAM,OAASqB,EAC5B,KAAMrB,EAAK,IAAI,KACf,OAAQA,EAAK,IAAI,OAASiC,EAC1B,OAAQjC,EAAK,IAAI,OAASiC,CAC3B,EACD,IAAK,CACH,GAAGjC,EAAK,GACpB,CACS,EACDA,EAAK,IAAM,CACT,GAAGD,EAAM,KACV,EACGC,EAAK,MAAM,SAAWA,EAAK,IAAI,OACjC,OAAO,OAAOA,EAAMD,CAAK,GAEzB0D,EAAO,OAAOG,EAAY,EAAG,CAAC,QAAS7D,EAAO2D,CAAO,EAAG,CAAC,OAAQ3D,EAAO2D,CAAO,CAAC,EAChFE,GAAc,EAExB,CACMA,GACN,CAEE,OAAOH,CACT,CCtMO,MAAMvD,GAAW,CACrB,GAAKoD,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKW,EACR,EAGaC,GAAiB,CAC3B,GAAKC,EACR,EAGaC,GAAc,CACzB,CAAC,EAAE,EAAGC,EACN,CAAC,EAAE,EAAGA,EACL,GAAKA,CACR,EAGahC,GAAO,CACjB,GAAKiC,GACL,GAAKC,EACL,GAAK,CAACC,GAAiBD,CAAa,EACpC,GAAKE,GACL,GAAKD,GACL,GAAKD,EACL,GAAKG,EACL,IAAMA,CACT,EAGa7B,GAAS,CACnB,GAAK8B,GACL,GAAKC,EACR,EAGa7B,GAAO,CAClB,CAAC,EAAE,EAAG8B,EACN,CAAC,EAAE,EAAGA,EACN,CAAC,EAAE,EAAGA,EACL,GAAKC,GACL,GAAKH,GACL,GAAKI,EACL,GAAK,CAACC,GAAUC,EAAQ,EACxB,GAAKC,GACL,GAAK,CAACC,GAAiBP,EAAe,EACtC,GAAKQ,GACL,GAAKL,EACL,GAAKM,EACR,EAGaC,GAAa,CACxB,KAAM,CAACP,EAAWQ,EAAW,CAC/B,EAGaC,GAAmB,CAC9B,KAAM,CAAC,GAAI,EAAE,CACf,EAGaC,GAAU,CACrB,KAAM,CAAA,CACR,oNCxBO,SAASC,GAAgBC,EAAQC,EAAYC,EAAM,CAExD,IAAI1E,EAAQ,CACV,aAAc,GACd,OAAQ,EACR,KAAM0E,GAAQA,EAAK,MAAQ,EAC3B,OAAQA,GAAQA,EAAK,QAAU,EAC/B,OAAQA,GAAQA,EAAK,QAAU,CAChC,EAED,MAAMC,EAAc,CAAE,EAEhBC,EAAuB,CAAE,EAE/B,IAAIlC,EAAS,CAAE,EAEXtD,EAAQ,CAAE,EASd,MAAMhB,EAAU,CACd,QAASyG,EAAiBC,CAAqB,EAC/C,MAAOD,EAAiBE,CAAiB,EACzC,QAAAC,EACA,MAAAxC,EACA,KAAAyC,EACA,UAAWJ,EAAiBE,EAAmB,CAC7C,UAAW,EACZ,CAAA,CACF,EAOKxC,EAAU,CACd,KAAM,KACN,eAAgB,CAAE,EAClB,WAAA2C,EACA,OAAQ,CAAE,EACV,IAAAC,EACA,OAAAX,EACA,SAAU,KACV,eAAAY,EACA,YAAAC,EACA,MAAAC,CACD,EAOD,IAAIC,EAAQd,EAAW,SAAS,KAAKlC,EAASnE,CAAO,EAQrD,OAAIqG,EAAW,YACbG,EAAqB,KAAKH,CAAU,EAE/BlC,EAGP,SAAS+C,EAAME,EAAO,CAKpB,OAJA9C,EAAS+C,GAAK/C,EAAQ8C,CAAK,EAC3BE,EAAM,EAGFhD,EAAOA,EAAO,OAAS,CAAC,IAAM,KACzB,CAAE,GAEXiD,EAAUlB,EAAY,CAAC,EAGvBlC,EAAQ,OAASqD,GAAWhB,EAAsBrC,EAAQ,OAAQA,CAAO,EAClEA,EAAQ,OACnB,CAOE,SAAS6C,EAAexG,EAAOiH,EAAY,CACzC,OAAOC,GAAgBT,EAAYzG,CAAK,EAAGiH,CAAU,CACzD,CAGE,SAASR,EAAYzG,EAAO,CAC1B,OAAOmH,GAAYrD,EAAQ9D,CAAK,CACpC,CAGE,SAASuG,GAAM,CAEb,KAAM,CACJ,aAAAa,EACA,OAAAC,EACA,KAAAC,EACA,OAAAC,EACA,OAAAC,CACN,EAAQpG,EACJ,MAAO,CACL,aAAAgG,EACA,OAAAC,EACA,KAAAC,EACA,OAAAC,EACA,OAAAC,CACD,CACL,CAGE,SAASlB,EAAWmB,EAAO,CACzB1B,EAAY0B,EAAM,IAAI,EAAIA,EAAM,OAChCC,EAAyB,CAC7B,CAiBE,SAASZ,GAAO,CAEd,IAAIa,EACJ,KAAOvG,EAAM,OAAS0C,EAAO,QAAQ,CACnC,MAAMG,EAAQH,EAAO1C,EAAM,MAAM,EAGjC,GAAI,OAAO6C,GAAU,SAKnB,IAJA0D,EAAavG,EAAM,OACfA,EAAM,aAAe,IACvBA,EAAM,aAAe,GAEhBA,EAAM,SAAWuG,GAAcvG,EAAM,aAAe6C,EAAM,QAC/D2D,EAAG3D,EAAM,WAAW7C,EAAM,YAAY,CAAC,OAGzCwG,EAAG3D,CAAK,CAEhB,CACA,CAUE,SAAS2D,EAAG/H,EAAM,CAGhB8G,EAAQA,EAAM9G,CAAI,CACtB,CAGE,SAASuG,EAAQvG,EAAM,CACjBK,EAAmBL,CAAI,GACzBuB,EAAM,OACNA,EAAM,OAAS,EACfA,EAAM,QAAUvB,IAAS,GAAK,EAAI,EAClC6H,EAAyB,GAChB7H,IAAS,KAClBuB,EAAM,SACNA,EAAM,UAIJA,EAAM,aAAe,EACvBA,EAAM,UAENA,EAAM,eAGFA,EAAM,eAIV0C,EAAO1C,EAAM,MAAM,EAAE,SACnBA,EAAM,aAAe,GACrBA,EAAM,WAKVuC,EAAQ,SAAW9D,CAIvB,CAGE,SAAS+D,EAAMiE,EAAMC,EAAQ,CAG3B,MAAM9H,EAAQ8H,GAAU,CAAE,EAC1B,OAAA9H,EAAM,KAAO6H,EACb7H,EAAM,MAAQuG,EAAK,EACnB5C,EAAQ,OAAO,KAAK,CAAC,QAAS3D,EAAO2D,CAAO,CAAC,EAC7CnD,EAAM,KAAKR,CAAK,EACTA,CACX,CAGE,SAASqG,EAAKwB,EAAM,CAClB,MAAM7H,EAAQQ,EAAM,IAAK,EACzB,OAAAR,EAAM,IAAMuG,EAAK,EACjB5C,EAAQ,OAAO,KAAK,CAAC,OAAQ3D,EAAO2D,CAAO,CAAC,EACrC3D,CACX,CAOE,SAASkG,EAAsB6B,EAAWC,EAAM,CAC9CjB,EAAUgB,EAAWC,EAAK,IAAI,CAClC,CAOE,SAAS7B,EAAkB8B,EAAGD,EAAM,CAClCA,EAAK,QAAS,CAClB,CAUE,SAAS/B,EAAiBiC,EAAUJ,EAAQ,CAC1C,OAAOK,EAeP,SAASA,EAAK/E,EAAYgF,EAAaC,EAAY,CAEjD,IAAIC,EAEAC,EAEAC,EAEAR,EACJ,OAAO,MAAM,QAAQ5E,CAAU,EAC/BqF,EAAuBrF,CAAU,EAAI,aAAcA,EAEnDqF,EAAuB,CAA0BrF,CAAU,CAAE,EAAIsF,GAAsBtF,CAAU,EAUjG,SAASsF,GAAsBC,EAAK,CAClC,OAAO9H,EAGP,SAASA,EAAMhB,EAAM,CACnB,MAAM+I,EAAO/I,IAAS,MAAQ8I,EAAI9I,CAAI,EAChCgJ,EAAMhJ,IAAS,MAAQ8I,EAAI,KAC3BpF,GAAO,CAGb,GAAI,MAAM,QAAQqF,CAAI,EAAIA,EAAOA,EAAO,CAACA,CAAI,EAAI,CAAE,EAAG,GAAI,MAAM,QAAQC,CAAG,EAAIA,EAAMA,EAAM,CAACA,CAAG,EAAI,CAAA,CAAG,EACtG,OAAOJ,EAAuBlF,EAAI,EAAE1D,CAAI,CAClD,CACA,CAUM,SAAS4I,EAAuBlF,EAAM,CAGpC,OAFA+E,EAAmB/E,EACnBgF,EAAiB,EACbhF,EAAK,SAAW,EACX8E,EAEFS,EAAgBvF,EAAKgF,CAAc,CAAC,CACnD,CAUM,SAASO,EAAgBf,EAAW,CAClC,OAAOlH,EAGP,SAASA,EAAMhB,EAAM,CAanB,OARAmI,EAAOe,EAAO,EACdP,EAAmBT,EACdA,EAAU,UACbpE,EAAQ,iBAAmBoE,GAKzBA,EAAU,MAAQpE,EAAQ,OAAO,WAAW,QAAQ,KAAK,SAASoE,EAAU,IAAI,EAC3E1F,EAAQ,EAEV0F,EAAU,SAAS,KAI1BD,EAAS,OAAO,OAAO,OAAO,OAAOnE,CAAO,EAAGmE,CAAM,EAAInE,EAASnE,EAAS4C,GAAIC,CAAG,EAAExC,CAAI,CAClG,CACA,CAGM,SAASuC,GAAGvC,EAAM,CAEhB,OAAAqI,EAASM,EAAkBR,CAAI,EACxBI,CACf,CAGM,SAAS/F,EAAIxC,EAAM,CAGjB,OADAmI,EAAK,QAAS,EACV,EAAEO,EAAiBD,EAAiB,OAC/BQ,EAAgBR,EAAiBC,CAAc,CAAC,EAElDF,CACf,CACA,CACA,CAUE,SAAStB,EAAUgB,EAAWjC,EAAM,CAC9BiC,EAAU,YAAc,CAAC/B,EAAqB,SAAS+B,CAAS,GAClE/B,EAAqB,KAAK+B,CAAS,EAEjCA,EAAU,SACZxG,EAAOoC,EAAQ,OAAQmC,EAAMnC,EAAQ,OAAO,OAASmC,EAAMiC,EAAU,QAAQpE,EAAQ,OAAO,MAAMmC,CAAI,EAAGnC,CAAO,CAAC,EAE/GoE,EAAU,YACZpE,EAAQ,OAASoE,EAAU,UAAUpE,EAAQ,OAAQA,CAAO,EAElE,CAQE,SAASoF,GAAQ,CACf,MAAMC,EAAazC,EAAK,EAClB0C,EAAgBtF,EAAQ,SACxBuF,EAAwBvF,EAAQ,iBAChCwF,EAAmBxF,EAAQ,OAAO,OAClCyF,EAAa,MAAM,KAAK5I,CAAK,EACnC,MAAO,CACL,KAAM2I,EACN,QAAAE,CACD,EAQD,SAASA,GAAU,CACjBjI,EAAQ4H,EACRrF,EAAQ,SAAWsF,EACnBtF,EAAQ,iBAAmBuF,EAC3BvF,EAAQ,OAAO,OAASwF,EACxB3I,EAAQ4I,EACR1B,EAAyB,CAC/B,CACA,CASE,SAASA,GAA0B,CAC7BtG,EAAM,QAAQ2E,GAAe3E,EAAM,OAAS,IAC9CA,EAAM,OAAS2E,EAAY3E,EAAM,IAAI,EACrCA,EAAM,QAAU2E,EAAY3E,EAAM,IAAI,EAAI,EAEhD,CACA,CAYA,SAAS+F,GAAYrD,EAAQ9D,EAAO,CAClC,MAAMsJ,EAAatJ,EAAM,MAAM,OACzBuJ,EAAmBvJ,EAAM,MAAM,aAC/BwJ,EAAWxJ,EAAM,IAAI,OACrByJ,EAAiBzJ,EAAM,IAAI,aAEjC,IAAI0J,EACJ,GAAIJ,IAAeE,EAEjBE,EAAO,CAAC5F,EAAOwF,CAAU,EAAE,MAAMC,EAAkBE,CAAc,CAAC,MAC7D,CAEL,GADAC,EAAO5F,EAAO,MAAMwF,EAAYE,CAAQ,EACpCD,EAAmB,GAAI,CACzB,MAAMI,EAAOD,EAAK,CAAC,EACf,OAAOC,GAAS,SAClBD,EAAK,CAAC,EAAIC,EAAK,MAAMJ,CAAgB,EAErCG,EAAK,MAAO,CAEpB,CACQD,EAAiB,GAEnBC,EAAK,KAAK5F,EAAO0F,CAAQ,EAAE,MAAM,EAAGC,CAAc,CAAC,CAEzD,CACE,OAAOC,CACT,CAYA,SAASxC,GAAgBpD,EAAQmD,EAAY,CAC3C,IAAI3F,EAAQ,GAEZ,MAAMsI,EAAS,CAAE,EAEjB,IAAIC,EACJ,KAAO,EAAEvI,EAAQwC,EAAO,QAAQ,CAC9B,MAAMG,EAAQH,EAAOxC,CAAK,EAE1B,IAAImG,EACJ,GAAI,OAAOxD,GAAU,SACnBwD,EAAQxD,MACH,QAAQA,EAAK,CAClB,IAAK,GACH,CACEwD,EAAQ,KACR,KACV,CACM,IAAK,GACH,CACEA,EAAQ;AAAA,EACR,KACV,CACM,IAAK,GACH,CACEA,EAAQ;AAAA,EACR,KACV,CACM,IAAK,GACH,CACEA,EAAQR,EAAa,IAAM,IAC3B,KACV,CACM,IAAK,GACH,CACE,GAAI,CAACA,GAAc4C,EAAO,SAC1BpC,EAAQ,IACR,KACV,CACM,QAGIA,EAAQ,OAAO,aAAaxD,CAAK,CAE3C,CACI4F,EAAQ5F,IAAU,GAClB2F,EAAO,KAAKnC,CAAK,CACrB,CACE,OAAOmC,EAAO,KAAK,EAAE,CACvB,CCzkBO,SAASE,GAAMC,EAAS,CAM7B,MAAMnE,EAAS,CACb,WAJFoE,GAAkB,CAACC,GAAmB,IAFrBF,GAAW,CAAE,GAEqB,YAAc,CAAE,CAAC,CAAC,EAKnE,QAASG,EAAO5K,EAAO,EACvB,QAAS,CAAE,EACX,SAAU4K,EAAO/J,EAAQ,EACzB,KAAM+J,EAAO5H,EAAI,EACjB,KAAM,CAAE,EACR,OAAQ4H,EAAOpH,EAAM,EACrB,KAAMoH,EAAOlH,EAAI,CAClB,EACD,OAAO4C,EAQP,SAASsE,EAAO1H,EAAS,CACvB,OAAO2H,EAEP,SAASA,EAAQrE,EAAM,CACrB,OAAOH,GAAgBC,EAAQpD,EAASsD,CAAI,CAClD,CACA,CACA,CC3CO,SAASsE,GAAY1G,EAAQ,CAClC,KAAO,CAAC2G,GAAY3G,CAAM,GAAG,CAG7B,OAAOA,CACT,CCAA,MAAM4G,GAAS,cAMR,SAASC,IAAa,CAC3B,IAAIhD,EAAS,EACTiD,EAAS,GAET3J,EAAQ,GAER4J,EACJ,OAAOC,EAIP,SAASA,EAAajD,EAAOkD,EAAUC,EAAK,CAE1C,MAAM9G,EAAS,CAAE,EAEjB,IAAI+G,EAEAC,EAEAC,EAEAC,EAEAnL,EAWJ,IAVA4H,EAAQ+C,GAAU,OAAO/C,GAAU,SAAWA,EAAM,SAAQ,EAAK,IAAI,YAAYkD,GAAY,MAAS,EAAE,OAAOlD,CAAK,GACpHsD,EAAgB,EAChBP,EAAS,GACL3J,IAEE4G,EAAM,WAAW,CAAC,IAAM,OAC1BsD,IAEFlK,EAAQ,QAEHkK,EAAgBtD,EAAM,QAAQ,CAKnC,GAJA6C,GAAO,UAAYS,EACnBF,EAAQP,GAAO,KAAK7C,CAAK,EACzBuD,EAAcH,GAASA,EAAM,QAAU,OAAYA,EAAM,MAAQpD,EAAM,OACvE5H,EAAO4H,EAAM,WAAWuD,CAAW,EAC/B,CAACH,EAAO,CACVL,EAAS/C,EAAM,MAAMsD,CAAa,EAClC,KACR,CACM,GAAIlL,IAAS,IAAMkL,IAAkBC,GAAeP,EAClD3G,EAAO,KAAK,EAAE,EACd2G,EAAmB,WAUnB,QARIA,IACF3G,EAAO,KAAK,EAAE,EACd2G,EAAmB,QAEjBM,EAAgBC,IAClBlH,EAAO,KAAK2D,EAAM,MAAMsD,EAAeC,CAAW,CAAC,EACnDzD,GAAUyD,EAAcD,GAElBlL,EAAI,CACV,IAAK,GACH,CACEiE,EAAO,KAAK,KAAK,EACjByD,IACA,KACd,CACU,IAAK,GACH,CAGE,IAFAuD,EAAO,KAAK,KAAKvD,EAAS,CAAC,EAAI,EAC/BzD,EAAO,KAAK,EAAE,EACPyD,IAAWuD,GAAMhH,EAAO,KAAK,EAAE,EACtC,KACd,CACU,IAAK,IACH,CACEA,EAAO,KAAK,EAAE,EACdyD,EAAS,EACT,KACd,CACU,QAEIkD,EAAmB,GACnBlD,EAAS,CAEvB,CAEMwD,EAAgBC,EAAc,CACpC,CACI,OAAIJ,IACEH,GAAkB3G,EAAO,KAAK,EAAE,EAChC0G,GAAQ1G,EAAO,KAAK0G,CAAM,EAC9B1G,EAAO,KAAK,IAAI,GAEXA,CACX,CACA","x_google_ignoreList":[0,1,2,3,4,5,6,7,8]}